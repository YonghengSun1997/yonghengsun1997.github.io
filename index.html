<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Hong Wang</title>

</head>
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable">
<tr>
<td> <a href="./"><img src="./Figures/Hong.png" alt="" height="180px" /></a>&nbsp;</td>
<td align="left">
<p>
<font size="4">Hong Wang (王 红)</font><br />
<br />
<a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a><br />
<br />
Tencent Building, Shennan Avenue, ShenZhen, China<br />
<br />
Email: hazelhwang@tencent.com
<br />
[<a class="p1" href="https://scholar.google.com/citations?user=I5RH0CwAAAAJ&amp;hl=en" target="_blank">Google Scholar</a>]
[<a class="p2" href="https://github.com/hongwang01" target="_blank">Github</a>]
[<a href="https://www.researchgate.net/profile/Hong-Wang-150" target="_blank">ResearchGate</a>]
[<a href="http://www.linkedin.com/in/hwang~DL" target="_blank">Linkedin</a>]
</p>
</td>
</tr></table>

<h2>Biography</h2>
<p> I am currently a researcher at Tencent, ShenZhen,
    working with Dr. <a href="https://sites.google.com/site/yefengzheng/" target="_blank">Yefeng Zheng (IEEE Fellow)</a>.
    I received my Ph.D. degree from School of Mathematics and Statistics, Xi'an Jiaotong University, China, in 2021, 
    under the supervision of Prof. <a href="https://gr.xjtu.edu.cn/en/web/dymeng" target="_blank">Deyu Meng</a>.
    Before that, I received my M.Sc degree under the supervision of <a href="https://person.zju.edu.cn/en/zhaoyangzhang/">Prof. Zhaoyang Zhang </a>from
    School of Information and Electronical Engineer, Zhejiang University, in 2018, and the B.S. degree from School of Communication and
    Information Engineer, Nanjing University of Posts and Telecommunications, in 2015.
  </p>


<h2>Research Interest</h2>
Currently, I work in the field of medical image analysis and natural image restoration. Specifically, I mainly investigate how to combine traditional 
model-driven method and data-driven deep learning techniques for effective and interpretable image processing. Recently, I focus on the following research topics:
<ul>
<li>Deep Unfolding Image Restoration</li>
<li>Bayesian Methods in Image Processing</li>
<li>Natural Image Restoration (such as, derain/super-resolution/denoise/deblur/low-light enhancement)</li>
<li>CT Reconstruction (such as, metal artifact reduction/low-dose/sparse-view/limited-angle)</li>
<li>MRI Reconstruction (such as, fast imaging/super-resolution/multi-contrast reconstruction)</li>
<li>Other Medical Image Analysis (including classification/segmentation/detection)</li>
</ul>


<h2>Research Experiences</h2>
<table class="imgtable">
<tr>
    <td align="left">
            <img src="./Figures/Tencent.jpg" alt="" height="90px" width="170px"/>
    </td>
    <td>
        <p><a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a>, ShenZhen, China</p>
        <p> Senior Researcher, Feb. 2022 ~ present</p>
        <p>Supervisor: Dr. <a href="https://sites.google.com/site/yefengzheng/" target="_blank">Yefeng Zheng (IEEE Fellow)</a></p>
    </td>
</tr>
<tr>
    <td align="left">
            <img src="./Figures/Tencent.jpg" alt="" height="90px" width="170px"/>
    </td>
    <td>
        <p><a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a>, ShenZhen, China</p>
        <p>Research Intern (Tencent Rhino Bird Elite Talent Program), Sep. 2020 ~ Jan. 2022</p>
        <p>Supervisor: Dr. <a href="https://sites.google.com/site/yefengzheng/" target="_blank">Yefeng Zheng (IEEE Fellow)</a>, Dr. <a href="https://scholar.google.com/citations?user=WsKu4EMAAAAJ&hl=en" target="_blank">Yuexiang Li</a></p>
    </td>
</tr>  
</table>


<h2>News</h2>
<ul>
<li>The pretrained-models for InDuDoNet and InDuDoNet+ have been released.</li>
<li>The code and pretrained-model for DICDNet have been released.</li>
<li>One paper is accepted in TNNLS 2022.</li>
<li>One paper is accepted in MedIA 2022.</li>
<li>One paper is accepted in AAAI 2023.</li>
<li>One paper is accpted in ECCV 2022 (<a class="p1" target="_blank">Oral</a>).</li>
<li>One paper is accepted in MICCAI 2022.</li>
<li>One paper is accepted in IJCAI 2022.</li>    
</ul>

    
<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Selected Publications
<a style="color:Black" class="p1" href="https://scholar.google.com/citations?user=I5RH0CwAAAAJ&amp;hl=en" target="_blank">
    <font size="2"> [Full List]</font></a>
</h2>

<table class="imgtable">

<!--TNNLS 2022-->
<tr>
<td><img class="proj_thumb" src="./Figures/DRCDNet_TNNLS2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">RCDNet: An Interpretable Rain Convolutional Dictionary Network for Single Image Deraining</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Qian Zhao, Yuexiang Li, Yong Liang, Yefeng Zheng, Deyu Meng<br>
IEEE Transactions on Neural Networks and Learning Systems</i> (<b>TNNLS</b>), 2022.<br>
[<a href= "https://arxiv.org/abs/2107.06808" target="_blank">Paper</a>] 
[<a href="https://github.com/hongwang01/DRCDNet" target="_blank">Code</a>] 
</p> </td>
</tr>


<!--MedIA 2022-->
<tr>
<td><img class="proj_thumb" src="./Figures/InDuDoNet+_MedIA2022.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">InDuDoNet+: A Deep Unfolding Dual Domain Network for Metal Artifact Reduction in CT Images</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Haimiao Zhang, Deyu Meng, Yefeng Zheng<br>
Medical Image Analysis</i>(<b>MedIA</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2112.12660.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/InDuDoNet_plus" target="_blank">Code</a>]
</p> </td>
</tr>


<!--AAAI 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/ClassFormer_AAAI2023.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">ClassFormer: Exploring Class-aware Dependency with Transformer for Medical Image Segmentation</p>
<p class="pub_author">Huimin Huang, Shiao Xie, Lanfen Lin, Ruofeng Tong, Yen-Wei Chen, <b>Hong Wang</b>, Yuexiang Li, Yawen Huang, Yefeng Zheng<br>
Thirty-Seventh AAAI Conference on Artificial Intelligence</i>(<b>AAAI</b>), 2023.<br>
</p> </td>
</tr>



<!--ECCV 2022-->
<tr>
<td><img class="proj_thumb" src="./Figures/KXNet_ECCV2022.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">KXNet: A Model-Driven Deep Neural Network for Blind Super-Resolution</p>
<p class="pub_author">Jiahong Fu, <b>Hong Wang</b>, Qi Xie, Qian Zhao, Deyu Meng, Zongben Xu<br>
European Conference on Computer Vision (<a class="p1" target="_blank">Oral</a>)</i>(<b>ECCV</b>), 2022.<br>
[<a href= "https://github.com/jiahong-fu/KXNet" target="_blank">Paper</a>]
[<a href="https://github.com/jiahong-fu/KXNet" target="_blank">Code</a>]
</p> </td>
</tr>    

<!-- MICCAI 2022, OSCNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/OSCNet_MICCAI2022.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Orientation-Shared Convolution Representation for CT Metal Artifact Learning</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Yuexiang Li, Yawen Huang, Deyu Meng, Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2022.<br>
[<a href= "   " target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>]
</p> </td>
</tr>



<!-- IJCAI 2022, ACDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/ACDNet_IJCAI2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Adaptive Convolutional Dictionary Network for CT Metal Artifact Reduction</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Deyu Meng, Yefeng Zheng<br>
31st International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2205.07471.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/ACDNet" target="_blank">Code</a>]
</p> </td>
</tr>

    
<!--SCIS 2022 Survey-->
<tr>
<td><img class="proj_thumb" src="./Figures/Survey_SCIS2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Survey on Rain Removal From Videos or A Single Image</p>
<p class="pub_author"><b>Hong Wang</b>, Yichen Wu, Minghan Li, Qian Zhao, Deyu Meng<br>
SCIENCE CHINA Information Sciences</i>(<b>SCIS</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/1909.08326.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/Video-and-Single-Image-Deraining" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- TMI 2021, DICDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/DICDNet_TMI2021.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">DICDNet: Deep Interpretable Convolutional Dictionary Network for Metal Artifact Reduction in CT Images</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Nanjun He, Kai Ma, Deyu Meng, Yefeng Zheng<br>
IEEE Transactions on Medical Imaging (<b>TMI</b>), 2021.<br>
[<a href= "https://github.com/hongwang01/DICDNet" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/DICDNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- MICCAI 2021, InDuDoNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/InDuDoNet_MICCAI2021.png" alt="" height="85px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">InDuDoNet: An Interpretable Dual Domain Network for CT Metal Artifact Reduction</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Haimiao Zhang, Kai Ma, Deyu Meng, Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention  (<b>MICCAI</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2109.05298.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/InDuDoNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- CVPR 2021, VRGNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/VRGNet_CVPR2021.png" alt="" height="70px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">From Rain Generation to Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>, Zongsheng Yue, Qi Xie, Qian Zhao, Yefeng Zheng, Deyu Meng<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021.<br>
[<a href= "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_From_Rain_Generation_to_Rain_Removal_CVPR_2021_paper.html" target="_blank">Paper</a>] 
[<a href="https://github.com/hongwang01/VRGNet" target="_blank">Code</a>] 
</p> </td>
</tr>
    



<!-- KBS 2021 SRNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/SRNet_KBS2021.png" alt="" height="116px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Structural Residual Learning for Single Image Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>, Yichen Wu, Qi Xie, Qian Zhao, Yong Liang, Shijun Zhang, Deyu Meng<br>
Knowledge-Based Systems</i> (<b>KBS</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2005.09228.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/SRNet" target="_blank">Code</a>]
</p> </td>
</tr>

<!--RAUNA 2021 Arxiv-->
<tr>
<td><img class="proj_thumb" src="./Figures/RAUNA_Arxiv2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Low-light Image Enhancement by Retinex Based Algorithm Unrolling and Adjustment</p>
<p class="pub_author">Xinyi Liu, Qi Xie, Qian Zhao, <b>Hong Wang</b>, Deyu Meng<br>
International Journal of Computer Vision(Under Review)</i>(<b>IJCV</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2202.05972.pdf" target="_blank">Paper</a>]
</p> </td>
</tr>

<!-- CVPR 2020, RCDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/RCDNet_CVPR2020.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">A Model-driven Deep Neural Network for Single Image Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Qian Zhao, Deyu Meng<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020.<br>
[<a href= "https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_A_Model-Driven_Deep_Neural_Network_for_Single_Image_Rain_Removal_CVPR_2020_paper.html" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/RCDNet" target="_blank">Code</a>]
</p> </td>
</tr>

<!-- IJMLC 2020-->
<tr>
<td><img class="proj_thumb" src="./Figures/IJMCL2020.png" alt="" height="80px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Single Image Rain Streaks Removal: A Review and An Exploration</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Yichen Wu, Qian Zhao, Deyu Meng<br>
International Journal of Machine Learning and Cybernetics (<b>IJMLC</b>), 2020.<br>
[<a href= "https://link.springer.com/article/10.1007/s13042-020-01061-2" target="_blank">Paper</a>]
</p> </td>
</tr>

<!-- NC 2020, GAN-->
<tr>
<td><img class="proj_thumb" src="./Figures/Neurocomputing2020.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Selective Generative Adversarial Network for Raindrop Removal From A Single Image</p>
<p class="pub_author">Mingwen Shao, Le Li, <b>Hong Wang</b>, Deyu Meng<br>
Neurocomputing (<b>NC</b>), 2020.<br>
[<a href= "https://www.sciencedirect.com/science/article/abs/pii/S0925231220315861" target="_blank">Paper</a>]
</p> </td>
</tr>

<table>

<!--Honors -->
<a id="honors" class="anchor"></a>
<h2>Honors</h2>
<p>2018.09-2021.12 (Xi'an Jiaotong University): </p>
<font size="2">
<ul>
<li>Outstanding Graduate Student of Shaanxi Province</li>
<li>National Scholarship for Graduate Students (<2%) (<b>highest national wide scholarship for students in China</b>)</li>
<li>Academic star best Popularity Award(<b>Top1 in Xi'an Jiaotong University</b>)</li>
<li>Academic star nomination award (<b>Top13 in Xi'an Jiaotong University</b>)</li>
<li>2nd size for Tencent Rhino Bird Elite Talent(<0.1%), Best Style Award(<0.1%)</li>
<li>Huawei Scholarship (<1%)</li>
<li>Outstanding graduate student of Xi’an Jiaotong University(<b>2 times</b>)</li>
<li>1st size for Scholarship of Xi’an Jiaotong University</li>
<li>3rd size for National Graduate Mathematical modeling Contest (<5%)</li>
<li>Tencent Rhino Bird Elite Talent Program</li>
</ul>
</font>

<p>2015.09-2018.03 (Zhejiang University): </p>
<font size="2">
<ul>
<li>Outstanding graduate student of Zhejiang University</li>
<li>National Scholarship for Graduate Students (<2%) (<b>highest national wide scholarship for students in China</b>)</li>
<li>Outstanding Graduate Student Cadre of Zhejiang University</li>
<li>Merit Graduate Student of Zhejiang University(<b>2 times</b>)</li>
<li>Samsung Scholarship (<3%)</li>
<li>1st size for National Graduate Electronical Design Competition (<1%)</li>
</ul>
</font>

<p>2011.09-2015.06 (Nanjing University of Posts and Telecommunications): </p>
<font size="2">
<ul>
<li>Outstanding undergraduate student of NUPT</li>
<li>National Scholarship for Undergraduate Students (<1%, <b>3 times</b>) (<b>highest national wide scholarship for students in China</b>)</li>
<li>China Telecom Scholarship (<1%)</li>
<li>Hengtong First Prize Scholarship (<1%)</li>
<li>1st size (Meritorious Winner) of International Mathematical Contest in Modeling (MCM) (<1%)</li>
<li>Provincial Merit Student Award (<1%)</li>
<li>Pacemaker to Creative Student of NUPT(<b>Top10 in NUPT</b>)</li>
<li>1st size for Advanced Mathematics Competition in Jiangsu Province (<5%)</li>
<li>1st size for scholarship of NUPT (<5%, <b>3 times</b>)</li>
<li>Pacemaker to Merit Student of NUPT (<5%, <b>3 times</b>)</li>
</ul>
</font>

<!-- Talks-->
<a id="talks" class="anchor"></a>
<h2>Talks</h2>
<font size="2"> 
<ul> 
<li> 2022.12.11 <a href="https://mp.weixin.qq.com/s/ZsGQ1uoaJeR0fIg5gmJVHA" target="_blank">[VALSE Student Webinar "面向底层视觉任务的基础算法" 青年学者论坛]</a></li>
<li> 2022.11.13 <a href="https://mp.weixin.qq.com/s/4mCA7pvlz3Tqn_zavb-tIg" target="_blank">[中国体视学学会智能成像分会第一届有方青年学术论坛]，<a href="https://pan.baidu.com/s/1Y0Hrfeg-g3kGCTvO5A-8pw" target="_blank">[PPT]</a>, password: abcd </li>
</ul>
</font>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>
<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Medical Imaging (TMI)</li>
<li>IEEE Transactions on Communications (TCOM)</li>
<li>Knowledge Based Systems (KBS)</li>
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</li>
<li>IEEE International Conference on Computer Vision (ICCV)</li>
<li>European Conference on Computer Vision (ECCV)</li>
<li>Association for the Advancement of Artificial Intelligence (AAAI)</li>
<li>International Joint Conference on Artificial Intelligence (IJCAI) (<b>Outstanding SPC for IJCAI2019</b>)</li>
<li>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</li>
</ul>
</font>

<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
